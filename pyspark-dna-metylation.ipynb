{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-31T10:36:30.766904Z",
     "iopub.status.busy": "2025-10-31T10:36:30.766648Z",
     "iopub.status.idle": "2025-10-31T10:36:43.786588Z",
     "shell.execute_reply": "2025-10-31T10:36:43.785694Z",
     "shell.execute_reply.started": "2025-10-31T10:36:30.766883Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/05 11:20:24 WARN Utils: Your hostname, mw-OptiPlex-7050, resolves to a loopback address: 127.0.1.1; using 10.2.6.194 instead (on interface enp0s31f6)\n",
      "25/11/05 11:20:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/05 11:20:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/11/05 11:20:29 WARN SQLConf: The SQL config 'spark.sql.adaptive.shuffle.targetPostShuffleInputSize' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.adaptive.advisoryPartitionSizeInBytes' instead of it.\n",
      "25/11/05 11:20:29 WARN SQLConf: The SQL config 'spark.sql.adaptive.shuffle.targetPostShuffleInputSize' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.adaptive.advisoryPartitionSizeInBytes' instead of it.\n",
      "25/11/05 11:20:29 WARN SQLConf: The SQL config 'spark.sql.adaptive.shuffle.targetPostShuffleInputSize' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.adaptive.advisoryPartitionSizeInBytes' instead of it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- case_barcode: string (nullable = true)\n",
      " |-- probe_id_ids: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- beta_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- chromosome: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ðŸ’¡ (Opcjonalnie) wymuÅ› wiÄ™kszy rozmiar sterty JVM\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--driver-memory 12g --executor-memory 12g pyspark-shell\"\n",
    "\n",
    "# ðŸ”§ Inicjalizacja SparkSession z wiÄ™kszÄ… pamiÄ™ciÄ… i optymalizacjÄ…\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master(\"local[*]\")  # uÅ¼ywa wszystkich rdzeni\n",
    "    .appName(\"DNA_Methylation_All_Parquet\")\n",
    "    # WiÄ™cej RAM\n",
    "    .config(\"spark.driver.memory\", \"12g\")\n",
    "    .config(\"spark.executor.memory\", \"12g\")\n",
    "    .config(\"spark.memory.fraction\", \"0.8\")        # 80% pamiÄ™ci dla zadaÅ„\n",
    "    .config(\"spark.memory.storageFraction\", \"0.3\") # czÄ™Å›Ä‡ na cache\n",
    "    # WiÄ™ksze strony pamiÄ™ci\n",
    "    .config(\"spark.storage.memoryMapThreshold\", \"2m\")\n",
    "    # Unikaj OOM przez adaptacyjne przetwarzanie\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "    .config(\"spark.sql.adaptive.shuffle.targetPostShuffleInputSize\", \"64MB\")\n",
    "    # Deduplikacja kluczy map (np. przy map_from_arrays)\n",
    "    .config(\"spark.sql.mapKeyDedupPolicy\", \"LAST_WIN\")\n",
    "    # UÅ‚atwia debugging\n",
    "    .config(\"spark.ui.showConsoleProgress\", \"true\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# ðŸ”¹ ÅšcieÅ¼ka do katalogu z plikami\n",
    "dataset_path = \"/home/mw/.cache/kagglehub/datasets/martininf1n1ty/dna-methylation-adnotated/versions/1\"\n",
    "\n",
    "# ðŸ”¹ Wczytanie wszystkich plikÃ³w Parquet rekurencyjnie\n",
    "merged_df = (\n",
    "    spark.read\n",
    "    .option(\"recursiveFileLookup\", \"true\")\n",
    "    .parquet(dataset_path)\n",
    ")\n",
    "\n",
    "# ðŸ”¹ Dodanie kolumny z nazwÄ… pliku (np. chromosome = chr1, chr2, ...)\n",
    "merged_df = merged_df.withColumn(\n",
    "    \"chromosome\",\n",
    "    F.regexp_extract(F.input_file_name(), r\"([^/]+)\\.parquet$\", 1)\n",
    ")\n",
    "\n",
    "# ðŸ”¹ (Dla bezpieczeÅ„stwa) zrepartycjonuj dane, Å¼eby nie Å‚adowaÄ‡ wszystkiego do jednej partycji\n",
    "merged_df = merged_df.repartition(16, \"chromosome\")\n",
    "\n",
    "# ðŸ”¹ WyÅ›wietlenie przykÅ‚adowych danych\n",
    "#print(f\"Liczba wierszy: {merged_df.count()}\")\n",
    "#merged_df.show(5, truncate=False)\n",
    "merged_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:36:54.511132Z",
     "iopub.status.busy": "2025-10-31T10:36:54.510443Z",
     "iopub.status.idle": "2025-10-31T10:36:54.752774Z",
     "shell.execute_reply": "2025-10-31T10:36:54.751880Z",
     "shell.execute_reply.started": "2025-10-31T10:36:54.511091Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- case_barcode: string (nullable = true)\n",
      " |-- chromosome: string (nullable = false)\n",
      " |-- probe_id_id: string (nullable = true)\n",
      " |-- beta_value: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql import functions as F\n",
    "\n",
    "# ðŸ”¹ Rozwijamy obie tablice rÃ³wnolegle\n",
    "exploded_df = merged_df.withColumn(\n",
    "    \"zipped\",\n",
    "    F.arrays_zip(\"probe_id_ids\", \"beta_values\")\n",
    ").withColumn(\n",
    "    \"exploded\",\n",
    "    F.explode(\"zipped\")\n",
    ").select(\n",
    "    \"case_barcode\",\n",
    "    \"chromosome\",\n",
    "    F.col(\"exploded.probe_id_ids\").alias(\"probe_id_id\"),\n",
    "    F.col(\"exploded.beta_values\").alias(\"beta_value\")\n",
    ")\n",
    "\n",
    "# ðŸ”¹ WyÅ›wietl przykÅ‚adowe dane i schemat\n",
    "#exploded_df.show(5, truncate=False)\n",
    "exploded_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:36:59.160024Z",
     "iopub.status.busy": "2025-10-31T10:36:59.159735Z",
     "iopub.status.idle": "2025-10-31T10:38:32.600652Z",
     "shell.execute_reply": "2025-10-31T10:38:32.598651Z",
     "shell.execute_reply.started": "2025-10-31T10:36:59.160002Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:======================================================>  (22 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----------+------------------+\n",
      "|case_barcode|chromosome|probe_id_id|        beta_value|\n",
      "+------------+----------+-----------+------------------+\n",
      "|TCGA-BR-4276|     chr11| cg00080012|0.0120308692210344|\n",
      "|TCGA-BR-4276|     chr11| cg00080012|0.0127937002970355|\n",
      "|TCGA-BR-4276|     chr11| cg00146096|0.0123743793715371|\n",
      "|TCGA-BR-4276|     chr11| cg00146096|0.0186264167163925|\n",
      "|TCGA-BR-4276|     chr11| cg00554702| 0.105780696728702|\n",
      "|TCGA-BR-4276|     chr11| cg00554702|   0.1195274389606|\n",
      "|TCGA-BR-4276|     chr11| cg00858899|0.0312394159831404|\n",
      "|TCGA-BR-4276|     chr11| cg00858899|0.0325718500447315|\n",
      "|TCGA-BR-4276|     chr11| cg00901652|0.0742616877956292|\n",
      "|TCGA-BR-4276|     chr11| cg00901652|0.0474890419650844|\n",
      "|TCGA-BR-4276|     chr11| cg00908551|0.0686619257058537|\n",
      "|TCGA-BR-4276|     chr11| cg00908551|0.0452899832671019|\n",
      "|TCGA-BR-4276|     chr11| cg00953256| 0.643713811274543|\n",
      "|TCGA-BR-4276|     chr11| cg00953256| 0.310383809463714|\n",
      "|TCGA-BR-4276|     chr11| cg01120308| 0.113675853409038|\n",
      "|TCGA-BR-4276|     chr11| cg01120308|0.0184356718607785|\n",
      "|TCGA-BR-4276|     chr11| cg01442799|0.0243926655058193|\n",
      "|TCGA-BR-4276|     chr11| cg01442799|0.0196993868283931|\n",
      "|TCGA-BR-4276|     chr11| cg01693350| 0.698322472879716|\n",
      "|TCGA-BR-4276|     chr11| cg01693350| 0.104987519098116|\n",
      "+------------+----------+-----------+------------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "exploded_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:38:51.780663Z",
     "iopub.status.busy": "2025-10-31T10:38:51.779809Z",
     "iopub.status.idle": "2025-10-31T10:43:17.898539Z",
     "shell.execute_reply": "2025-10-31T10:43:17.897186Z",
     "shell.execute_reply.started": "2025-10-31T10:38:51.780629Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:==============>                                          (6 + 8) / 23]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ðŸ”¹ Krok 2: policz, w ilu pacjentach wystÄ™puje dana sonda (per chromosom)\n",
    "probe_counts = (\n",
    "    exploded_df\n",
    "    .select(\"chromosome\", \"probe_id_id\", \"case_barcode\")\n",
    "    .distinct()  # unikamy duplikatÃ³w\n",
    "    .groupBy(\"chromosome\", \"probe_id_id\")\n",
    "    .agg(F.countDistinct(\"case_barcode\").alias(\"n_patients_with_probe\"))\n",
    ")\n",
    "first_quantile = 8894\n",
    "\n",
    "# ðŸ”¹ Krok 3: wybierz tylko te sondy, ktÃ³re wystÄ™pujÄ… u wszystkich pacjentÃ³w\n",
    "common_probes = probe_counts.filter(F.col(\"n_patients_with_probe\") >= first_quantile)\n",
    "\n",
    "#common_probes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/05 11:40:10 WARN TaskMemoryManager: Failed to allocate a page (536870912 bytes), try again.\n",
      "25/11/05 11:43:00 WARN TaskMemoryManager: Failed to allocate a page (2147483648 bytes), try again.\n",
      "25/11/05 11:43:00 WARN TaskMemoryManager: Failed to allocate a page (2147483648 bytes), try again.\n",
      "25/11/05 11:43:00 WARN TaskMemoryManager: Failed to allocate a page (1532228038 bytes), try again.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#probe_counts.coalesce(1).write.option(\"header\",\"true\").csv(\"probe_counts_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:===================================================>    (21 + 2) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+------------+------------------+\n",
      "|chromosome|probe_id_id|case_barcode|beta_value        |\n",
      "+----------+-----------+------------+------------------+\n",
      "|chr11     |cg00080012 |TCGA-BR-4276|0.0120308692210344|\n",
      "|chr11     |cg00080012 |TCGA-BR-4276|0.0127937002970355|\n",
      "|chr11     |cg00146096 |TCGA-BR-4276|0.0123743793715371|\n",
      "|chr11     |cg00146096 |TCGA-BR-4276|0.0186264167163925|\n",
      "|chr11     |cg00554702 |TCGA-BR-4276|0.105780696728702 |\n",
      "+----------+-----------+------------+------------------+\n",
      "only showing top 5 rows\n",
      "root\n",
      " |-- chromosome: string (nullable = false)\n",
      " |-- probe_id_id: string (nullable = true)\n",
      " |-- case_barcode: string (nullable = true)\n",
      " |-- beta_value: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#ðŸ”¹ Krok 4: doÅ‚Ä…cz je z powrotem do exploded_df\n",
    "filtered_df = (\n",
    "    exploded_df.join(\n",
    "        common_probes.select(\"chromosome\", \"probe_id_id\"),\n",
    "        on=[\"chromosome\", \"probe_id_id\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# ðŸ”¹ Krok 5: podglÄ…d i schemat\n",
    "filtered_df.show(5, truncate=False)\n",
    "filtered_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:===>             (5 + 8) / 23][Stage 36:>                (0 + 0) / 23]\r"
     ]
    }
   ],
   "source": [
    "patients_per_chr = (\n",
    "    exploded_df\n",
    "    .select(\"case_barcode\", \"chromosome\")\n",
    "    .distinct()\n",
    ")\n",
    "probes_per_chr = (\n",
    "    exploded_df\n",
    "    .select(\"chromosome\", \"probe_id_id\")\n",
    "    .distinct()\n",
    ")\n",
    "full_grid = (\n",
    "    patients_per_chr\n",
    "    .join(probes_per_chr, on=\"chromosome\", how=\"inner\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df_with_nans = (\n",
    "    full_grid\n",
    "    .join(\n",
    "        exploded_df.select(\"case_barcode\", \"chromosome\", \"probe_id_id\", \"beta_value\"),\n",
    "        on=[\"case_barcode\", \"chromosome\", \"probe_id_id\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_path = \"dna_methylation_common_probes.parquet\"\n",
    "\n",
    "(\n",
    "    exploded_df_with_nans\n",
    "    .coalesce(1)   # wymusza zapis do jednego pliku (jedna partycja)\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(output_path)\n",
    ")\n",
    "\n",
    "print(f\"âœ… Wynik zapisany do: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-31T10:20:05.092528Z",
     "iopub.status.idle": "2025-10-31T10:20:05.093131Z",
     "shell.execute_reply": "2025-10-31T10:20:05.092930Z",
     "shell.execute_reply.started": "2025-10-31T10:20:05.092911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "df_genes = pd.read_csv('https://raw.githubusercontent.com/marcin119a/data/refs/heads/main/joined.csv')\n",
    "genes = \"', '\".join(list(df_genes['Hugo Symbol'].unique()))\n",
    "dataset = 'isb-cgc-bq.annotations.methylation_annotation_hg38_gdc_current'\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT DISTINCT\n",
    "  g.symbol AS gene_symbol,\n",
    "  CpG_probe_id,\n",
    "  chromosome,\n",
    "  position\n",
    "FROM `{dataset}`,\n",
    "UNNEST(genes) AS g\n",
    "WHERE g.symbol IN ('{genes}')\n",
    "ORDER BY g.symbol\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "probles_for_onkodb = query_job.to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-31T10:20:05.094163Z",
     "iopub.status.idle": "2025-10-31T10:20:05.094530Z",
     "shell.execute_reply": "2025-10-31T10:20:05.094358Z",
     "shell.execute_reply.started": "2025-10-31T10:20:05.094342Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# probles_for_onkodb = spark.createDataFrame(probles_for_onkodb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-31T10:20:05.096174Z",
     "iopub.status.idle": "2025-10-31T10:20:05.096553Z",
     "shell.execute_reply": "2025-10-31T10:20:05.096380Z",
     "shell.execute_reply.started": "2025-10-31T10:20:05.096362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql import functions as F\n",
    "\n",
    "# ðŸ”¹ Rozwijamy obie tablice rÃ³wnolegle\n",
    "exploded_df = merged_df.withColumn(\n",
    "    \"zipped\",\n",
    "    F.arrays_zip(\"probe_id_ids\", \"beta_values\")\n",
    ").withColumn(\n",
    "    \"exploded\",\n",
    "    F.explode(\"zipped\")\n",
    ").select(\n",
    "    \"case_barcode\",\n",
    "    \"chromosome\",\n",
    "    F.col(\"exploded.probe_id_ids\").alias(\"probe_id_id\"),\n",
    "    F.col(\"exploded.beta_values\").alias(\"beta_value\")\n",
    ")\n",
    "\n",
    "# ðŸ”¹ WyÅ›wietl przykÅ‚adowe dane i schemat\n",
    "#exploded_df.show(5, truncate=False)\n",
    "exploded_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:21:35.802440Z",
     "iopub.status.busy": "2025-10-31T10:21:35.802079Z",
     "iopub.status.idle": "2025-10-31T10:21:35.813733Z",
     "shell.execute_reply": "2025-10-31T10:21:35.812250Z",
     "shell.execute_reply.started": "2025-10-31T10:21:35.802412Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exploded_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37/65414418.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexploded_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'exploded_df' is not defined"
     ]
    }
   ],
   "source": [
    "exploded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T18:22:15.635940Z",
     "iopub.status.busy": "2025-10-29T18:22:15.635482Z",
     "iopub.status.idle": "2025-10-29T18:22:15.917472Z",
     "shell.execute_reply": "2025-10-29T18:22:15.913838Z",
     "shell.execute_reply.started": "2025-10-29T18:22:15.635897Z"
    }
   },
   "source": [
    "# joined_df = (\n",
    "    exploded_df\n",
    "    .join(probles_for_onkodb, on=[\"chromosome\"], how=\"left\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T18:22:24.626543Z",
     "iopub.status.busy": "2025-10-29T18:22:24.626212Z",
     "iopub.status.idle": "2025-10-29T18:23:53.597101Z",
     "shell.execute_reply": "2025-10-29T18:23:53.595390Z",
     "shell.execute_reply.started": "2025-10-29T18:22:24.626521Z"
    }
   },
   "source": [
    "# grouped_df = (\n",
    "    exploded_df\n",
    "    .groupBy(\"case_barcode\", \"chromosome\")\n",
    "    .agg(\n",
    "        F.sort_array(\n",
    "            F.collect_list(\n",
    "                F.struct(\"probe_id_id\", \"beta_value\")\n",
    "            ),\n",
    "            asc=True\n",
    "        ).alias(\"sorted_pairs\")\n",
    "    )\n",
    "    .select(\n",
    "        \"case_barcode\",\n",
    "        \"chromosome\",\n",
    "        F.expr(\"transform(sorted_pairs, x -> x.probe_id_id)\").alias(\"probe_id_ids\"),\n",
    "        F.expr(\"transform(sorted_pairs, x -> x.beta_value)\").alias(\"beta_values\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(grouped_df.show(3, truncate=False))\n",
    "print(ggrouped_df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T18:24:29.619826Z",
     "iopub.status.busy": "2025-10-29T18:24:29.619420Z",
     "iopub.status.idle": "2025-10-29T18:26:04.352785Z",
     "shell.execute_reply": "2025-10-29T18:26:04.351891Z",
     "shell.execute_reply.started": "2025-10-29T18:24:29.619781Z"
    }
   },
   "source": [
    "# grouped_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8600607,
     "sourceId": 13542957,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
